#!/usr/bin/env python3
"""
RAG ç³»ç»Ÿè¯„ä¼°è„šæœ¬
v2.0 - æ‰¹é‡è¯„ä¼°é—®ç­”æ•ˆæœ

ç”¨æ³•:
    python scripts/eval.py [--input data/eval/questions.jsonl] [--output data/eval/results.jsonl]

è¾“å…¥æ–‡ä»¶æ ¼å¼ (questions.jsonl):
    {"question": "é—®é¢˜1", "expected": "é¢„æœŸå…³é”®è¯æˆ–ç­”æ¡ˆç‰‡æ®µ"}
    {"question": "é—®é¢˜2", "expected": "é¢„æœŸå…³é”®è¯æˆ–ç­”æ¡ˆç‰‡æ®µ"}

è¾“å‡ºæ–‡ä»¶æ ¼å¼ (results.jsonl):
    {"question": "...", "answer": "...", "sources": [...], "confidence": "...", "latency_ms": ..., "expected": "...", "match": true/false}
"""
import os
import sys
import json
import time
import argparse
from pathlib import Path
from typing import List, Dict, Any
import requests
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(PROJECT_ROOT / ".env")


def load_questions(input_file: Path) -> List[Dict[str, Any]]:
    """åŠ è½½è¯„ä¼°é—®é¢˜"""
    questions = []
    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                questions.append(json.loads(line))
    return questions


def evaluate_question(
    question: str,
    expected: str = None,
    base_url: str = "http://localhost:5001",
    agentic_mode: bool = False,
) -> Dict[str, Any]:
    """è¯„ä¼°å•ä¸ªé—®é¢˜"""
    start_time = time.time()
    
    try:
        response = requests.post(
            f"{base_url}/chat",
            json={
                "user_id": "eval_user",
                "thread_id": "eval_thread",
                "message": question,
                "top_k": 5,
                "agentic_mode": agentic_mode,
            },
            timeout=120,
        )
        response.raise_for_status()
        data = response.json()
        
        latency_ms = int((time.time() - start_time) * 1000)
        
        # ç®€å•åŒ¹é…æ£€æŸ¥
        match = False
        if expected:
            answer_lower = data.get("answer", "").lower()
            expected_lower = expected.lower()
            # æ£€æŸ¥é¢„æœŸå…³é”®è¯æ˜¯å¦å‡ºç°åœ¨ç­”æ¡ˆä¸­
            keywords = [kw.strip() for kw in expected_lower.split(",")]
            match = all(kw in answer_lower for kw in keywords)
        
        return {
            "question": question,
            "answer": data.get("answer", ""),
            "sources": [
                {
                    "source": s.get("source"),
                    "chunk_id": s.get("chunk_id"),
                    "score": s.get("score"),
                }
                for s in data.get("sources", [])
            ],
            "confidence": data.get("confidence"),
            "latency_ms": latency_ms,
            "expected": expected,
            "match": match,
            "error": None,
        }
        
    except Exception as e:
        latency_ms = int((time.time() - start_time) * 1000)
        return {
            "question": question,
            "answer": None,
            "sources": [],
            "confidence": None,
            "latency_ms": latency_ms,
            "expected": expected,
            "match": False,
            "error": str(e),
        }


def run_evaluation(
    input_file: Path,
    output_file: Path,
    base_url: str = "http://localhost:5001",
    agentic_mode: bool = False,
) -> Dict[str, Any]:
    """è¿è¡Œå®Œæ•´è¯„ä¼°"""
    questions = load_questions(input_file)
    print(f"ğŸ“‹ åŠ è½½äº† {len(questions)} ä¸ªè¯„ä¼°é—®é¢˜")
    
    results = []
    total_latency = 0
    match_count = 0
    error_count = 0
    
    for i, q in enumerate(questions, 1):
        question = q.get("question", "")
        expected = q.get("expected", "")
        
        print(f"  [{i}/{len(questions)}] è¯„ä¼°: {question[:50]}...")
        
        result = evaluate_question(
            question=question,
            expected=expected,
            base_url=base_url,
            agentic_mode=agentic_mode,
        )
        
        results.append(result)
        total_latency += result["latency_ms"]
        
        if result["error"]:
            error_count += 1
            print(f"    âŒ é”™è¯¯: {result['error']}")
        elif result["match"]:
            match_count += 1
            print(f"    âœ… åŒ¹é… ({result['latency_ms']}ms)")
        else:
            print(f"    âš ï¸ ä¸åŒ¹é… ({result['latency_ms']}ms)")
    
    # ä¿å­˜ç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        for r in results:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")
    
    # ç»Ÿè®¡æ‘˜è¦
    summary = {
        "total_questions": len(questions),
        "match_count": match_count,
        "error_count": error_count,
        "match_rate": match_count / len(questions) if questions else 0,
        "avg_latency_ms": total_latency / len(questions) if questions else 0,
        "agentic_mode": agentic_mode,
    }
    
    return summary


def main():
    parser = argparse.ArgumentParser(description="RAG ç³»ç»Ÿè¯„ä¼°è„šæœ¬")
    parser.add_argument(
        "--input", "-i",
        type=Path,
        default=PROJECT_ROOT / "data/eval/questions.jsonl",
        help="è¾“å…¥çš„é—®é¢˜æ–‡ä»¶ (jsonl æ ¼å¼)"
    )
    parser.add_argument(
        "--output", "-o",
        type=Path,
        default=PROJECT_ROOT / "data/eval/results.jsonl",
        help="è¾“å‡ºçš„ç»“æœæ–‡ä»¶ (jsonl æ ¼å¼)"
    )
    parser.add_argument(
        "--url", "-u",
        type=str,
        default="http://localhost:5001",
        help="API æœåŠ¡åœ°å€"
    )
    parser.add_argument(
        "--agentic", "-a",
        action="store_true",
        help="ä½¿ç”¨ Agentic RAG æ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    if not args.input.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        print("è¯·åˆ›å»º questions.jsonl æ–‡ä»¶ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š")
        print('{"question": "é—®é¢˜å†…å®¹", "expected": "é¢„æœŸå…³é”®è¯"}')
        sys.exit(1)
    
    print("=" * 60)
    print("ğŸ”¬ RAG ç³»ç»Ÿè¯„ä¼°")
    print("=" * 60)
    print(f"ğŸ“¥ è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"ğŸ“¤ è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"ğŸŒ API åœ°å€: {args.url}")
    print(f"ğŸ¤– Agentic æ¨¡å¼: {'å¼€å¯' if args.agentic else 'å…³é—­'}")
    print("=" * 60)
    
    summary = run_evaluation(
        input_file=args.input,
        output_file=args.output,
        base_url=args.url,
        agentic_mode=args.agentic,
    )
    
    print("=" * 60)
    print("ğŸ“Š è¯„ä¼°ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"  æ€»é—®é¢˜æ•°: {summary['total_questions']}")
    print(f"  åŒ¹é…æ•°: {summary['match_count']}")
    print(f"  é”™è¯¯æ•°: {summary['error_count']}")
    print(f"  åŒ¹é…ç‡: {summary['match_rate']:.1%}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {summary['avg_latency_ms']:.0f}ms")
    print("=" * 60)
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {args.output}")


if __name__ == "__main__":
    main()

